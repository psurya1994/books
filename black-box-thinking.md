black-box-thinking.md

Summary:
This books talk about how humans / systems (health care, political, criminal unlike airlines, startups) are often biased and don't learn from failures. This is an inspiring book that helps me think more clearly about the "experts" and how they are flawed (and suggests good ideas on how to fix these problems). This knowledge will not only come in quite handy for me in future when I navigate systems, but also help think more clearly about my scientific work. This book has improved a different dimension of my thinking compared to the philosophy books I read. This book seems to add a dimension to my problem solving thinking. 

Rating: 8.5/10 

Chapter 1:
- Success hinges on how we react to failure.
- Health care and airlines have very different responses to failure. Airlines ensure failure doesn't happen again, leads to high safety rates. Health care does 400k deaths (and possibly 10 times more irreversibble harm) which are avoidable per year, which makes it the third biggest threat. These mistakes are made by well intentioned doctors. 
- Failure generally comes with reputational damage, which is why we don't openly acknowledge it. We often try to blame others for their mistakes and conceal our own. 
- Clinical trials have transformed the performance of the medical industry because they keep the human biases out. 
- Success can only happen when we admit our mistakes, learn from them and create a climate where it is safe to fail.
- Medical errors are stigmatized and related to incomeptence. 

Chapter 2:
- People narrow their fields of view when encountering problems, which makes them vulnerable to making trivial mistakes they haven't been thinking of.
	- because time seems to pass much faster than their brains estimate
	- because they are not sure if they should question an authority figure
	- attention is a scare resource, you can only focus on somethings, not all things. 
- experiments show that we underestimate time when we're solving hard problems (time flows by faster in our subjective experience).
- black box thinking: creating a system that helps us learn from failures. 
- analysing failure is far harder than it seem, but it's critical if we want ot improve. 

Chapter 3:
- Science is another area that's good at self correcting. Failure is seen as an opportunity to improve our understanding. 
- Adler's theories are unfalsifiable, especially inferiority complex: "behavior emerges from the need to prove oneself"
- To test the effectiveness of a theory, we need to test it in as many diverse settings as possible. 
- 10,000 hours is necessary for experitise, but it only happens if you have immediate feedback / error signal (deliberate practice). Which is why psychotherapists don't improve with experience. Delayed feedback makes learning harder.
- The teach students only the final theories but not the theories that died, this creates a blind stop for students. They fail to understand that repeated failure is necessary to come up with good theories. (I disagree with the author, none of my science colleugues suffer from this blindspot)
- <10% autopsys are conducted. we need to do more if we want to learn from them.

My thoughts:
- Always get a second opinion when you meet doctors. They didn't have deliberate practice, so they might not be good. They sometimes think their mistakes are correct because of the poor quality of feedback they have. 
- If you're going to a doctor:
	- Make sure they use checklists before surgery.
	- Make sure they got good sleep the night before. 

Chapter 4:
- Criminal system can learn from black box thinking too. 
- Type 1: error of commision (false positive). Type 2: error of ommision (false negative). Generally there's a tradeoff between these two errors by changing the threshold of evidence. But the way to reduce both is by investiagting failures. 
- We reframe evidence to fit our beliefs. If you put effort into getting something, you're biased to believe that it's good. 
- The cops / detectives find it hard to accept that they are wrong after wrongful convictions. This is a closed loop system that doesn't learn from failures putting lots of innocent people at risk of wrongful conviction. 

Chapter 5:
- People often fail to notice that they're invovled in closed loop thinking. They block mistakes from entering conscious thought. Counter evidence strengthens our belief. We keep moved the flag post on what is reasonable evidence for us to change our beliefs. 
- Most intelligent people are most vulnerable because they use their intelligence justify their cognitive dissonance. 
- Self esteem makes cognitive dissonance worse. 
- It's often the ones who have most to lose who are most effected by this. Examples: famous people but acknowledging mistake would be expensive.
- But that doesn't explain everything. We sometimes don't admit even when we're provided incentives to do so. Example: stock market, studies show that we hold bad stocks for far too long.
- An example where we make mistake: what's the pattern that generates the sequence 2, 4, 6? We say even and only test examples are agree to the hypothesis. We don't test patterns that disagree. This is why trying to falsify the theories we have in mind is extremely important. 

My thoughts:
- I need to be careful not to fall into this trap in my life (expert's cognitive disonnance). I can do it by:
	- Actively seeking opposing opinions and viewpoints.
	- Being early to admit your mistake. Not trying to show off your competence. Don't have an ego.
	- Be honest about what you don't understand. 

Chapter 6:
- There's evidence that when countries outlawed a specific scientific theory, the advanced rapidly declined. If you're not allowed to falsify the present theory, you can't make good progress.
- Even top people like Neil Tyson have false beliefs and find it hard to budge. 
- Human memory is very fallible. It changes with each recall. The questions asked to probe memories affect the memory we recollect.
- Innocence project realized that 75% of the wrongful convictions were based on flawed eyewitness testimony. Showing multiple suspects avoids the issue to some extent and doing it double blind. 
- False confessions lead to 30% of wrongful convictions. 
- If we want to reform the criminal system, we need individual organizations analysing these wrongful convictions. To reduce type 2 errors, we should also analyse perpetrators walking free.
- Study: judges parole decisions are based on how hungry they are. Juries are not reliable too. 

Chapter 7:
- To improve on something, we generally hire the experts in the area to work on it, but they might have a blind spot. It's important to make sure that these experts are diverse enough. 
- If you keep failing and learning from your failures, you'll eventually solve a difficult problem. 
- Economics struggles from rapid learning because of a lack of clear error signal. Entreprenuers don't (they learn from their and other people's failures, they fail fast).
- If you're unable to solve an intellectually hard problem theoretically, just get closer and closer using an error signal (eg. use some kind of evolutionary process).  (Like the biologists working on the nozzle problem)
- Technological process is a complex interplay between theoretical and practical knowledge in a upward spiral.
- We are hardwired to think that the world is simpler than it actually is. Which is why we make simple posthoc judgements about events. 
- You need to have failure before you succeed. 
- If you want to trust a company, look at their failures and course corrections they made than the narrative they present. What initial assumptions that they made turned out to be false? This is evidence that the company is on the right path.
- Charities which have low overheard / administrative costs might be ineffective because they don't explore and fail.

My thoughts:
- How can I apply this idea of trials and failures way of solving problems in my life?
	- Just throw different algorithms at the problem and see what performs best. Reasons from there. Don't try to theoretically estimate it if it's hard. (you can come up with the theory later, this is often faster)
	- Do things and learn from failures instead of trying to master all topics. Work on many side projects. Implement things. Fail. Learn from other's implementations. Keep consistently improving.
- Most sports journalists who criticize the captain for making the wrong decisions after the game don't realize that they are engaged in the narrative fallacy. 

Chapter 8:
- There's clear evidence that even experts have skewed interpretations in the absence of randomized control trials. It comes to the resuce because failure is clouded in ambiguity in the real world. 
- RCTs solves the issue that we can't run counterfactuals. 
- But there are no RCTs in the criminal justice system. 
- We need to be careful of selection bias when running surveys. 
- Narrative is far more convincing to the public and politicians than data from the RCT. This is the problem with politics that it's always run on narrative. 
- Don't be convinced by individual narratives you see on documentaries. It can't be trusted unless you run RCTs. 
- Same with rising kids, go by systematic reviews on RCTs. Don't rely on narratives. 
- In science, a "systematic review" analyses the data from all RCT and is the gold standard in science. 

Chapter 9: Marginal gains
- Break a big goal into small parts and deliver 1% improvement in each. This is what a coach did to get his cycling team win gold medals when most thought it was impossible. 
- Did world investment in poor countries help global poverty? People can make good arguments for and against. The greatest truth determiner is the RCT. But it's not possible to run RCT is whole countries. So, we should run RCTs on all the subprograms implemented in africa. 
- If we're rolling out big policies and investments, we should always test them with mini RCTs in some areas; before enforcing it on the whole country. The ony way to know if a policy works is to test it out in the real world.
- People argue that RCTs are inethical (why isn't everyone getting the best treatment given the data), but that's what helps civilization in the long term. 
- You need to focus on both aspects: improving performance and improving the feedback error signal. 
- The same idea is used by people building best engines in the world: they start with a MVP and keep iterating. 
- The F1 drivers analyse performance using all metric right after every race so that they can improve for the next time. 
- Most choices made by the company would be better if they were chosen by rapid feedback loops instead of human expert policies.
- How to win a hotdog eating competition? By doing repeated testing and tracking of what works and what doesn't. Fail repeatedly in small vigiorously tested ways to know for sure on what works and what doesn't. 

My thoughts:
- What are some ways in which I can apply the ideas of marginal improvement to my life?
	- Define the problem: does meditation help? Define the design space: [0 to 120 minutes]. Check how many page of books I'm able to read everyday. Maybe use BO to change the time? 

Chapter 10:
- Creativity is not a magical process. Creativity is a response to problems. You are creative only when you're solving problems, not when you're thinking into the ether. 
- You need people criticizing the ideas you come up with. Only when you have people disrupting your thought process through criticism do you make new associations. And creativity is just connecting different things. 
- Most scientific ideas come from discussion with collegues, not isolated thinking. Rest of the ideas happen during non-work hours. A some other during focused sessions (least number).
- Creativity / innovation is highly context dependant. 
- What you do after you get the idea is key. You need to do lots of iterations and testing to improve upon it. It needs disciplined focus. 

My thoughts: 
- What are some problems I face in life which need creativity?
	- Making YouTube videos. I have a lot of ideas, but don't want to spend too much time making the actual videos. What are some ways in which I can speed it up?
		- Create slides and track them? 
- Black box thinking might help with coming up with movie ideas. First test them on RCTs to see what scripts work best when you have multiple ideas. 
- I think randomized controlled trials have the potential to revolutionize the film industry. Before deciding which of several scripts you want to turn into a movie, run RCTs for evaluation instead of using your intuition. 

Chapter 11:
- If our first reaction after a mistake is to blame the other person, the other person will cover his mistakes. We should instead treat mistakes as a learning opportunity. 
- In any industry where there's incentive to hide mistakes, progress will be slow. 
- "If you make a honest mistake, we will never punish you." needs to be the culture in companies to flourish. 

Chapter 12:
- You cannot blame professionals if the person they're responsible for don't perform well (teachers, social workers, police). It would only make them cover up their flaws and creating a closed loop. It creates immense harm leads to fewer people applying for these roles. Blaming them doesn't increase accountability, giving them an open platform to share their mistakes does.
- When a public mistakes happen, we should be slow to censure the professionals involved before a proper investigation takes place. Doing this would make the other professionals in the area closed and impact their performance. 

Chapter 13:
- EEG study: People with fixed mindset don't learn from mistakes where as people with growth mindset do. We need to engage in our errors if we want to improve. 
- When you don't do well on something the first time you try it, see it as a learning opportunity. Not that you don't have the skill to do it better. 
- Grit is another imporatnt factor: "Setbacks don't discourage me", "I finish what I begin". 
- People with growth mindset are also better at recognizing their failures. 

Chapter 14:
- Kids are not afraid of failure. Failure is culturally learned. You can teach kids to reinterpret failure. Challenge them to fail.
- Be proud of failure. Wear failure like a bage of honor.
- People prefer giving excuses than accepting that they didn't put in the work.

Chapter 15:
- Even historically, fixed mindset without scientific method hindered progress.
- Free markets are effective because htey are allowed to fail.
- top-down: theoritical, bottom-up: error driven learning.
- Applying this to your own life:
	- Do you fail in your judgments? Do you have an error signal? Are your assumptions challenged by collecting data? 
	






